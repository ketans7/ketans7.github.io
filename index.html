<!doctype html>
<html>

<head>
  <title>Personal webpage</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-103598896-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" id="me" src="img/Profilepic.jpg">
          </div>
          <div class="flex-item flex-column">
            <h2>Ketan Sharma</h2>
            <p class="text">
              London, UK | <a href="https://www.linkedin.com/in/ketan-sharma-b7556a1b2/" target="_blank">LinkedIn</a> | <a href="https://github.com/ketan7sharma" target="_blank">GitHub</a><br>
              ketan7sharma@gmail.com | +44 07818980305 [cite: 72]
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2>Biography</h2>
            <hr>
            <p class="text">
              I'm a 22-year-old MSc Data Science & AI student at UAL Creative Computing Institute, London, UK, originally from Mumbai, India. [cite: 74] Specializing in computer vision, deep learning, and LLMs with professional experience as crowd technical director at DNEG. [cite: 75] I focus on MLOps, RAG systems, agentic AI, and scalable deployments on cloud and simulated systems. [cite: 76] I have experience working with Python, C++, TensorFlow, PyTorch, and a range of creative and technical tools for building AI-driven media solutions and real-time interactive experiences. [cite: 77] My recent projects include emotion-based media playback, AI-powered interactive systems, and optimization algorithms for scalable applications. [cite: 78] Coming from an underprivileged background, I've reached this position through merit and determination, and I'm known as a reliable team player with strong adaptability and communication skills. [cite: 79] I stay physically active through running and weightlifting, maintain aquariums, explore quantum computing, and enjoy cooking. [cite: 80] Always open to collaborations in AI, creative technology, and advanced coding challenges. [cite: 81]
            </p>
            <h3>Table of Content</h3>
            <ul>
              <li><a href="#skills">Key Skills</a></li>
              <li><a href="#education">Education</a></li>
              <li><a href="#employment">Employment</a></li>
              <li><a href="#projects">Projects</a></li>
              <li><a href="#languages">Languages</a></li>
              <li><a href="#hobbies">Hobbies</a></li>
            </ul>

            <h2 id="skills">Key Skills</h2>
            <hr>
            <ul>
                <li><b>Programming Languages:</b> Python, C++, JavaScript [cite: 84]</li>
                <li><b>Machine Learning Frameworks:</b> TensorFlow, PyTorch, Scikit-learn, Keras [cite: 85]</li>
                <li><b>Data Science Tools:</b> Pandas, NumPy, Matplotlib, Data Analysis, Data Wrangling [cite: 86]</li>
                <li><b>AI Specializations:</b> Computer Vision, Deep Learning, Natural Language Processing (NLP), Generative AI, Reinforcement Learning [cite: 87]</li>
                <li><b>Cloud Platforms:</b> AWS, Azure, Google Cloud Platform [cite: 88]</li>
                <li><b>Technical Capabilities:</b> Real-time Systems, Algorithmic Problem-Solving, Simulation, Optimization [cite: 89]</li>
            </ul>

            <h3>Personal Attributes</h3>
            <ul>
                <li><b>Team Player:</b> Collaborative approach with strong communication skills across diverse teams [cite: 93]</li>
                <li><b>Adaptable:</b> Quick to learn new technologies and adjust to changing project requirements [cite: 94]</li>
                <li><b>Reliable:</b> Consistent delivery of high-quality work with attention to detail [cite: 94]</li>
                <li><b>Innovation-Driven:</b> Passionate about applying cutting-edge AI solutions to real-world problems [cite: 95]</li>
                <li><b>Research-Oriented:</b> Strong analytical thinking and problem-solving capabilities [cite: 97]</li>
            </ul>

            <h2 id="education">Education</h2>
            <hr>
            <ul>
              <li><b>MSc, Data Science & AI for the Creative Industries</b>, UAL Creative Computing Institute, London, UK (2024-2025) [cite: 133]
                <ul>
                    <li>Specializing in Computer Vision, Deep Learning, and real-time AI applications [cite: 134]</li>
                    <li>Focus on applying AI algorithms to creative and industrial problem-solving [cite: 135]</li>
                </ul>
              </li>
              <li><b>BSc, Animation, Interactive Technology, Video Graphics & Special Effects</b>, Amity University Mumbai, Mumbai, India (2020-2023) 
                <ul>
                    <li>Developed strong technical foundation in creative technology and problem-solving [cite: 138]</li>
                    <li>Built expertise in digital content creation and technical workflows [cite: 138]</li>
                </ul>
              </li>
            </ul>

            <h2 id="employment">Employment</h2>
            <hr>
            <ul>
              <li><b>Crowd Technical Director</b>, DNEG, Mumbai, India (Jan 2022 - Jun 2023) [cite: 126]
                <ul>
                    <li>Developed and implemented sophisticated crowd simulations for film and television productions [cite: 127]</li>
                    <li>Applied algorithmic problem-solving using Python/C++ scripting to optimize crowd behaviors and large-scale scene efficiency [cite: 128]</li>
                    <li>Collaborated with VFX teams to integrate complex simulations, ensuring technical accuracy and artistic vision [cite: 129]</li>
                    <li>Managed technical workflows for large-scale projects, ensuring assets were properly structured and accessible [cite: 130]</li>
                </ul>
              </li>
            </ul>

            <h2 id="projects">Projects</h2>
            <hr>
            <li style="list-style: none;"><h3><b>Automated Music Festival Poster Image Generation</b></h3>
            <a href="https://github.com/cci-student/NLP-project" target="_blank">View Project</a>
            <ul>
                <li>Deep Learning Image Generation: Integrated Stable Diffusion 3 (SD3) and Florence-2 models for high-quality automated poster generation with advanced text-to-image synthesis capabilities [cite: 112]</li>
                <li>LLM-Powered Prompt Engineering: Implemented large language model integration for dynamic prompt optimization and refinement, enabling context-aware content generation [cite: 113]</li>
                <li>Hyper-Personalization Pipeline: Developed automated workflow for generating customized promotional content based on user demographics and preferences with scalable batch processing [cite: 114]</li>
                <li>Multi-Modal AI Integration: Combined computer vision models with natural language processing for intelligent text encoding and visual content generation [cite: 115]</li>
                <li>Production-Ready Workflow: Built end-to-end automation pipeline including image loading, resizing, text processing, generation, and output management with iterative refinement capabilities [cite: 116]</li>
                <li>Scalable Architecture: Designed system for processing multiple images with efficient resource management and automated quality control mechanisms [cite: 117]</li>
            </ul>
            </li>

            <li style="list-style: none;"><h3><b>Emotion Detection Model</b></h3>
            <a href="https://git.arts.ac.uk/23046385/AI-4-Media-Project-Ketan-Sharma" target="_blank">View Project</a>
            <ul>
                <li>Custom CNN Architecture: Built a 4-layer convolutional neural network with batch normalization and dropout regularization, achieving 82% accuracy on emotion classification across 7 emotional states. [cite: 101]</li>
                <li>Real-time Computer Vision Pipeline: Implemented an OpenCV-based face detection and emotion recognition system with optimized frame processing for real-time webcam input. [cite: 102]</li>
                <li>Advanced Model Training: Employed class-weighted loss functions, weighted random sampling, and data augmentation to handle imbalanced datasets and improve model generalization. [cite: 103]</li>
                <li>Multi-threaded Architecture: Designed a concurrent processing system with separate threads for video capture, emotion detection, and audio playback to ensure smooth real-time performance. [cite: 104]</li>
                <li>Audio Processing Integration: Integrated librosa for dynamic tempo scaling and time-stretching algorithms that modify music playback based on detected emotional states. [cite: 106]</li>
                <li>PyTorch Deep Learning: Utilized the PyTorch framework with the Adam optimizer, learning rate scheduling, and label smoothing for robust model training and convergence. [cite: 107]</li>
            </ul>
            </li>

            <li style="list-style: none;"><h3><b>Virtual Real-time Clothing Try-on System</b></h3>
            <a href="https://github.com/23046385/AI-Powered-Virtual-Try-On-System" target="_blank">View Project</a>
            <ul>
                <li>Currently building a real-time virtual fitting solution that enables users to try on clothing digitally using computer vision and augmented reality techniques [cite: 109]</li>
                <li>Project in active development phase [cite: 110]</li>
            </ul>
            </li>

            <li style="list-style: none;"><h3><b>Health Habit Buddy</b></h3>
            <a href="https://github.com/23046385/Health-Habit-Buddy" target="_blank">View Project</a>
            <ul>
                <li>Local AI Integration: Implemented offline-first architecture using Ollama and LLaMA 2 model for privacy-focused AI text generation without cloud dependencies [cite: 119]</li>
                <li>Streamlit Framework: Built clean, modern user interface using Streamlit with minimalist black-and-white design for optimal user experience [cite: 119]</li>
                <li>Privacy-Focused Architecture: Developed 100% local processing system ensuring user data remains on-device with no external data transmission [cite: 120]</li>
                <li>Personalized AI Messaging: Created intelligent encouragement system that generates contextual motivational messages based on user habit completion patterns [cite: 122]</li>
                <li>Offline-First Design: Engineered application to function completely offline, targeting wellness creators and health-conscious users prioritizing data privacy [cite: 124]</li>
            </ul>
            </li>

            <h2 id="languages">Languages</h2>
            <hr>
            <ul>
                <li>English: Fluent [cite: 140]</li>
                <li>Hindi: Native [cite: 140]</li>
                <li>Thethi: Native [cite: 140]</li>
                <li>Marathi: Conversational [cite: 140]</li>
            </ul>

            <h2 id="hobbies">Hobbies</h2>
            <hr>
            <p>I stay physically active through running and weightlifting, maintain aquariums, explore quantum computing, and enjoy cooking. [cite: 80]</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>

</html>